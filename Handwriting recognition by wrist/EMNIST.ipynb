{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Dependencies\n",
    "from IPython.display import Image, SVG\n",
    "import seaborn as sns\n",
    "\n",
    "# Filepaths, Numpy, Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#ignore warning messages \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Shape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emnist\n",
    "# Import Dataset(s)\n",
    "from emnist import list_datasets\n",
    "list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with 'letters'\n",
    "# Import \n",
    "from emnist import extract_training_samples\n",
    "images_train, labels_train = extract_training_samples('letters')\n",
    "from emnist import extract_test_samples\n",
    "images_test, labels_test = extract_test_samples('letters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of training and testing data\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(images_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images_train[0,:,:], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Data\n",
    "dims = images_train.shape[1] * images_train.shape[2]\n",
    "X_train = images_train.reshape(images_train.shape[0], dims)\n",
    "X_test = images_test.reshape(images_test.shape[0], dims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale to 0 -> 1 by dividing by max pixel value (255)\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "from keras.utils import np_utils # used to convert array of labeled data to one-hot vector\n",
    "# should be 26 but out of index?\n",
    "# Effects accuracy as have a class where their will be no results\n",
    "num_classes = 27\n",
    "y_train = np_utils.to_categorical(labels_train, num_classes)\n",
    "y_test = np_utils.to_categorical(labels_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Sequential model\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "#Layers\n",
    "\n",
    "# 1 - number of elements (pixels) in each image\n",
    "# Dense layer - when every node from previous layer is connected to each node in current layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "# Second Hidden Layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "\n",
    "# Output Layer - number of nodes corresponds to number of y labels\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"emnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"emnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: 1, B: 2, C: 3, D: 4, E: 5, F: 6, G: 7, H: 8, I: 9, J: 10, K: 11, L: 12, M: 13, N: 14, O: 15, P: 16, Q: 17, R: 18, S: 19, T: 20, U: 21, V: 22, W: 23, X: 24, Y: 25, Z: 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = np.expand_dims(X_train[8], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28,28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.expand_dims(X_train[22], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28,28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Custom Image \n",
    "\n",
    "The first test is mainly to see if importing works. I got the \"B\" (and all the testing letter images) from graphemica.com. \n",
    "This site contains larger images of font styles. I thought this affected the learning as the EMNIST set is created from actual writing. \n",
    "The first \"B\" is Times New Roman, and the test resulted in not predicting correctly. The second \"B\" is DejaVu Sans, Book. This \"B\" is bolder and more similar to the test data than the Times New Roman \"B\". This model will most likely work better with bolder images based off these observations. \n",
    "Note: These imported images are also NOT handwritten thus affecting conclusions about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"imageData/images/test2.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "#scale and flatten\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "\n",
    "# Plot and Predict\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"imageData/images/test5.png\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-Written Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pencil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = \"imageData/imPencil/pencil23.jpg\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image is tilted. Will loop through all images in file and rotate using the PILLOW library. The glob library is to help loop through multiple elements in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving flipped image and then testing\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "files = glob.glob(\"imageData/imPencil/*.jpg\")\n",
    "\n",
    "for infile in files:\n",
    "    image = Image.open(infile)\n",
    "    im = image.rotate(270)\n",
    "    im.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    im.save(infile + '_thumbnail', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try test again with flipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"imageData/imPencil/pencil23.jpg_thumbnail\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving flipped image and then testing\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "files = glob.glob(\"imageData/imPen/*.jpg\")\n",
    "\n",
    "for infile in files:\n",
    "    image = Image.open(infile)\n",
    "    im = image.rotate(270)\n",
    "    im.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    im.save(infile + '_thumbnail', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"imageData/imPen/pen9.jpg_thumbnail\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharpie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving flipped image and then testing\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "files = glob.glob(\"imageData/imSharpie/*.jpg\")\n",
    "\n",
    "for infile in files:\n",
    "    image = Image.open(infile)\n",
    "    im = image.rotate(270)\n",
    "    im.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    im.save(infile + '_thumbnail', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"imageData/imSharpie/sharpie11.jpg_thumbnail\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving flipped image and then testing\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "files = glob.glob(\"imageData/imMarker/*.jpg\")\n",
    "\n",
    "for infile in files:\n",
    "    image = Image.open(infile)\n",
    "    im = image.rotate(270)\n",
    "    im.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    im.save(infile + '_thumbnail', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"imageData/imMarker/marker15.jpg_thumbnail\"\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenCV to read handwritten letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'imageData/newImages/test1.jpg'\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "files = glob.glob(\"imageData/newImages/test1.jpg\")\n",
    "\n",
    "for infile in files:\n",
    "    image = Image.open(infile)\n",
    "    im = image.rotate(270)\n",
    "    im.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    im.save(infile + '_thumbnail', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'imageData/newImages/test1.jpg_thumbnail'\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('imageData/newImages/test2.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "resized = cv2.resize(gray, (28,28))\n",
    "# cv2.imshow('gray',gray)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imwrite('imageData/newImages/testGray2.jpg', resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'imageData/newImages/testGray2.jpg'\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('imageData/newImages/test3.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "resized = cv2.resize(gray, (28,28))\n",
    "# cv2.imshow('gray',gray)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imwrite('imageData/newImages/testGray3.jpg', resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'imageData/newImages/testGray3.jpg'\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('imageData/newImages/test4.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "resized = cv2.resize(gray, (28,28))\n",
    "# cv2.imshow('gray',gray)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imwrite('imageData/newImages/testGray4.jpg', resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'imageData/newImages/testGray4.jpg'\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image_size = (28,28)\n",
    "im = image.load_img(file, target_size=image_size, color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "image = img_to_array(im)\n",
    "\n",
    "image /= 255\n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28,28), cmap=plt.cm.Greys)\n",
    "\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
