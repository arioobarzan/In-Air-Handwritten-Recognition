{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Pose module\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize MediaPipe DrawingUtils module for landmark visualization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "# Lists to store wrist positions\n",
    "left_wrist_positions = []\n",
    "right_wrist_positions = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the pose estimation model\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Extract wrist landmarks\n",
    "    if results.pose_landmarks:\n",
    "        left_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "        right_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "        if left_wrist_landmark and right_wrist_landmark:\n",
    "            h, w, c = frame.shape\n",
    "            left_wrist_x = int(left_wrist_landmark.x * w)\n",
    "            left_wrist_y = int(left_wrist_landmark.y * h)\n",
    "            right_wrist_x = int(right_wrist_landmark.x * w)\n",
    "            right_wrist_y = int(right_wrist_landmark.y * h)\n",
    "\n",
    "            # Append wrist positions to the lists\n",
    "            left_wrist_positions.append((left_wrist_x, left_wrist_y))\n",
    "            right_wrist_positions.append((right_wrist_x, right_wrist_y))\n",
    "\n",
    "            # Draw wrist positions\n",
    "            for pos in left_wrist_positions:\n",
    "                cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
    "            for pos in right_wrist_positions:\n",
    "                cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw lines between wrist positions\n",
    "            for i in range(1, len(left_wrist_positions)):\n",
    "                cv2.line(frame, left_wrist_positions[i - 1], left_wrist_positions[i], (0, 255, 0), 2)\n",
    "            for i in range(1, len(right_wrist_positions)):\n",
    "                cv2.line(frame, right_wrist_positions[i - 1], right_wrist_positions[i], (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Wrist Tracking', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed and release the resources\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Pose module\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize MediaPipe DrawingUtils module for landmark visualization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "# Lists to store wrist positions\n",
    "left_wrist_positions = []\n",
    "right_wrist_positions = []\n",
    "\n",
    "# Initialize a flag to indicate whether to capture and save the image\n",
    "capture_image = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the pose estimation model\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Extract wrist landmarks\n",
    "    if results.pose_landmarks:\n",
    "        left_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "        right_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "        if left_wrist_landmark and right_wrist_landmark:\n",
    "            h, w, c = frame.shape\n",
    "            left_wrist_x = int(left_wrist_landmark.x * w)\n",
    "            left_wrist_y = int(left_wrist_landmark.y * h)\n",
    "            right_wrist_x = int(right_wrist_landmark.x * w)\n",
    "            right_wrist_y = int(right_wrist_landmark.y * h)\n",
    "\n",
    "            # Append wrist positions to the lists\n",
    "            left_wrist_positions.append((left_wrist_x, left_wrist_y))\n",
    "            right_wrist_positions.append((right_wrist_x, right_wrist_y))\n",
    "\n",
    "            # Draw wrist positions\n",
    "            for pos in left_wrist_positions:\n",
    "                cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
    "            for pos in right_wrist_positions:\n",
    "                cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw lines between wrist positions\n",
    "            for i in range(1, len(left_wrist_positions)):\n",
    "                cv2.line(frame, left_wrist_positions[i - 1], left_wrist_positions[i], (0, 255, 0), 2)\n",
    "            for i in range(1, len(right_wrist_positions)):\n",
    "                cv2.line(frame, right_wrist_positions[i - 1], right_wrist_positions[i], (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Wrist Tracking', frame)\n",
    "\n",
    "    # Check if 'c' is pressed to capture and save the image\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('c'):\n",
    "        capture_image = True\n",
    "\n",
    "    # Break the loop when 'q' is pressed and release the resources\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # If capture_image is True, save the frame as an image\n",
    "    if capture_image:\n",
    "        image_with_lines = frame.copy()\n",
    "\n",
    "        # Get the user's home directory and append the desktop path\n",
    "        desktop_path = os.path.expanduser(\"~\") + \"/Desktop/\"\n",
    "    \n",
    "        # Save the image with a unique filename on the desktop\n",
    "        image_filename = desktop_path + \"captured_image.jpg\"\n",
    "        cv2.imwrite(image_filename, image_with_lines)\n",
    "        \n",
    "        # Reset the capture_image flag\n",
    "        capture_image = False\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Initialize MediaPipe Pose module\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize MediaPipe DrawingUtils module for landmark visualization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "# Lists to store wrist positions\n",
    "left_wrist_positions = []\n",
    "right_wrist_positions = []\n",
    "\n",
    "# Initialize a flag to indicate whether to capture and save the image\n",
    "capture_image = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the pose estimation model\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Extract wrist landmarks\n",
    "    if results.pose_landmarks:\n",
    "        left_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "        right_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "        if left_wrist_landmark and right_wrist_landmark:\n",
    "            h, w, c = frame.shape\n",
    "            left_wrist_x = int(left_wrist_landmark.x * w)\n",
    "            left_wrist_y = int(left_wrist_landmark.y * h)\n",
    "            right_wrist_x = int(right_wrist_landmark.x * w)\n",
    "            right_wrist_y = int(right_wrist_landmark.y * h)\n",
    "\n",
    "            # Append wrist positions to the lists\n",
    "            left_wrist_positions.append((left_wrist_x, left_wrist_y))\n",
    "            right_wrist_positions.append((right_wrist_x, right_wrist_y))\n",
    "\n",
    "            # Draw wrist positions\n",
    "            for pos in left_wrist_positions:\n",
    "                cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
    "            for pos in right_wrist_positions:\n",
    "                cv2.circle(frame, pos, 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw lines between wrist positions\n",
    "            for i in range(1, len(left_wrist_positions)):\n",
    "                cv2.line(frame, left_wrist_positions[i - 1], left_wrist_positions[i], (0, 255, 0), 2)\n",
    "            for i in range(1, len(right_wrist_positions)):\n",
    "                cv2.line(frame, right_wrist_positions[i - 1], right_wrist_positions[i], (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Wrist Tracking', frame)\n",
    "\n",
    "    # Check if 'c' is pressed to capture and save the image\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('c'):\n",
    "        capture_image = True\n",
    "\n",
    "    # Break the loop when 'q' is pressed and release the resources\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # If capture_image is True, save the frame as an image\n",
    "    if capture_image:\n",
    "\n",
    "        # Create a blank white image\n",
    "        blank_image = np.ones_like(frame) * 255\n",
    "\n",
    "        # Draw the lines on the blank image\n",
    "        for i in range(1, len(left_wrist_positions)):\n",
    "            cv2.line(blank_image, left_wrist_positions[i - 1], left_wrist_positions[i], (0, 0, 0), 2)\n",
    "        for i in range(1, len(right_wrist_positions)):\n",
    "            cv2.line(blank_image, right_wrist_positions[i - 1], right_wrist_positions[i], (0, 0, 0), 2)\n",
    "\n",
    "        # Find the non-white pixels in the image\n",
    "        non_white_pixels = np.where(np.any(blank_image != 255, axis=-1))\n",
    "\n",
    "        # Crop the image to the non-white pixel region\n",
    "        min_y, max_y = non_white_pixels[0].min(), non_white_pixels[0].max()\n",
    "        min_x, max_x = non_white_pixels[1].min(), non_white_pixels[1].max()\n",
    "        cropped_image = blank_image[min_y:max_y+1, min_x:max_x+1]\n",
    "\n",
    "        # Generate a timestamp for the filename\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        # Save the cropped image with a unique filename on the desktop\n",
    "        desktop_path = os.path.expanduser(\"~\") + \"/Desktop/\"\n",
    "        image_filename = desktop_path + \"captured_lines_\" + timestamp + \".jpg\"\n",
    "        cv2.imwrite(image_filename, cropped_image)\n",
    "        print(\"Lines captured and saved on the desktop!\")\n",
    "\n",
    "        # Reset the capture_image flag\n",
    "        capture_image = False\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 --> Solve the background issue (This number is the finel --> So this code can Capture the drawn lines and save it to desktop as .jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Initialize MediaPipe Pose module\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize MediaPipe DrawingUtils module for landmark visualization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "# Lists to store wrist positions\n",
    "left_wrist_positions = []\n",
    "right_wrist_positions = []\n",
    "\n",
    "# Initialize a flag to indicate whether to capture and save the image\n",
    "capture_image = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the pose estimation model\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # Extract wrist landmarks\n",
    "    if results.pose_landmarks:\n",
    "        left_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "        right_wrist_landmark = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "\n",
    "        if left_wrist_landmark and right_wrist_landmark:\n",
    "            h, w, c = frame.shape\n",
    "            left_wrist_x = int(left_wrist_landmark.x * w)\n",
    "            left_wrist_y = int(left_wrist_landmark.y * h)\n",
    "            right_wrist_x = int(right_wrist_landmark.x * w)\n",
    "            right_wrist_y = int(right_wrist_landmark.y * h)\n",
    "\n",
    "            # Append wrist positions to the lists\n",
    "            left_wrist_positions.append((left_wrist_x, left_wrist_y))\n",
    "            right_wrist_positions.append((right_wrist_x, right_wrist_y))\n",
    "\n",
    "            # Draw wrist positions\n",
    "            for pos in left_wrist_positions:\n",
    "                cv2.circle(frame, pos, 16, (0, 255, 0), -1)\n",
    "            for pos in right_wrist_positions:\n",
    "                cv2.circle(frame, pos, 16, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw lines between wrist positions\n",
    "            for i in range(1, len(left_wrist_positions)):\n",
    "                cv2.line(frame, left_wrist_positions[i - 1], left_wrist_positions[i], (0, 255, 0), 12)\n",
    "            for i in range(1, len(right_wrist_positions)):\n",
    "                cv2.line(frame, right_wrist_positions[i - 1], right_wrist_positions[i], (0, 255, 0), 12)\n",
    "\n",
    "    # Flip the frame horizontally to correct the mirror effect\n",
    "    flipped_frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Wrist Tracking', flipped_frame)\n",
    "\n",
    "    # Check if 'c' is pressed to capture and save the image\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('s'):\n",
    "        capture_image = True\n",
    "\n",
    "    # Break the loop when 'q' is pressed and release the resources\n",
    "    if key & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    if key & 0xFF == ord('c'):\n",
    "        left_wrist_positions = []\n",
    "        right_wrist_positions = []\n",
    "\n",
    "    # If capture_image is True, save the frame as an image\n",
    "    if capture_image:\n",
    "\n",
    "        # Create a blank white image\n",
    "        blank_image = np.ones_like(frame) * 255\n",
    "\n",
    "        # Draw the lines on the blank image\n",
    "        for i in range(1, len(left_wrist_positions)):\n",
    "            cv2.line(blank_image, left_wrist_positions[i - 1], left_wrist_positions[i], (0, 0, 0), 32)\n",
    "        for i in range(1, len(right_wrist_positions)):\n",
    "            cv2.line(blank_image, right_wrist_positions[i - 1], right_wrist_positions[i], (0, 0, 0), 32)\n",
    "\n",
    "        # Find the non-white pixels in the image\n",
    "        non_white_pixels = np.where(np.any(blank_image != 255, axis=-1))\n",
    "\n",
    "        # Crop the image to the non-white pixel region\n",
    "        min_y, max_y = non_white_pixels[0].min(), non_white_pixels[0].max()\n",
    "        min_x, max_x = non_white_pixels[1].min(), non_white_pixels[1].max()\n",
    "        cropped_image = cv2.flip(blank_image[min_y:max_y+1, min_x:max_x+1] , 1)\n",
    "\n",
    "        # Generate a timestamp for the filename\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        # Save the cropped image with a unique filename on the desktop\n",
    "        desktop_path = os.path.expanduser(\"~\") + \"/Desktop/\"\n",
    "        image_filename = desktop_path + \"captured_lines_\" + timestamp + \".jpg\"\n",
    "        cv2.imwrite(image_filename, cropped_image)\n",
    "        print(\"Lines captured and saved on the desktop!\")\n",
    "\n",
    "        # Reset the capture_image flag\n",
    "        capture_image = False\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
