{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the hand points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the hands detection model\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            for landmark in landmarks.landmark:\n",
    "                x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "                cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Landmarks', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the index points and draw between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "bullet_points = []  # Initialize the bullet points list\n",
    "\n",
    "# Initialize a flag to indicate whether to capture and save the image\n",
    "capture_image = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the hands detection model\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            for idx, landmark in enumerate(landmarks.landmark):\n",
    "                # The index for the tip of the index finger is 8\n",
    "                if idx == 8:\n",
    "                    x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "                    bullet_points.append((x, y))  # Store the bullet point coordinates\n",
    "\n",
    "    # Draw lines between consecutive bullet points\n",
    "    for i in range(1, len(bullet_points)):\n",
    "        cv2.line(frame, bullet_points[i - 1], bullet_points[i], (255, 0, 0), 8)\n",
    "\n",
    "    # Draw bullet points on the frame\n",
    "    for bullet_point in bullet_points:\n",
    "        cv2.circle(frame, bullet_point, 12, (0, 255, 0), -1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Index Finger Movement', frame)\n",
    "\n",
    "    # Check for key press events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):  # Clear points and lines on 'c' key press\n",
    "        bullet_points = []\n",
    "    elif key == ord('s'):  # Save the lines in a white blank board\n",
    "        capture_image = True\n",
    "\n",
    "    # If capture_image is True, save the frame as an image\n",
    "    if capture_image:\n",
    "        blank_image = np.ones_like(frame) * 255\n",
    "\n",
    "        # Draw the lines on the blank image\n",
    "        for i in range(1, len(bullet_points)):\n",
    "            cv2.line(blank_image, bullet_points[i - 1], bullet_points[i], (0, 0, 0), 2)\n",
    "\n",
    "        non_white_pixels = np.where(np.any(blank_image != 255, axis=-1))\n",
    "\n",
    "        min_y, max_y = non_white_pixels[0].min(), non_white_pixels[0].max()\n",
    "        min_x, max_x = non_white_pixels[1].min(), non_white_pixels[1].max()\n",
    "        cropped_image = blank_image[min_y:max_y + 1, min_x:max_x + 1]\n",
    "\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        desktop_path = os.path.expanduser(\"~\") + \"/Desktop/\"\n",
    "        image_filename = desktop_path + \"captured_lines_\" + timestamp + \".jpg\"\n",
    "        cv2.imwrite(image_filename, cropped_image)\n",
    "        print(\"Lines captured and saved on the desktop!\")\n",
    "\n",
    "        capture_image = False\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(1)  # 1 == Webcam, 0 == mobile cam\n",
    "\n",
    "bullet_points = []  # Initialize the bullet points list\n",
    "\n",
    "# Initialize a flag to indicate whether to capture and save the image\n",
    "capture_image = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the hands detection model\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for landmarks in results.multi_hand_landmarks:\n",
    "            for idx, landmark in enumerate(landmarks.landmark):\n",
    "                # The index for the tip of the index finger is 8\n",
    "                if idx == 8:\n",
    "                    x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "                    bullet_points.append((x, y))  # Store the bullet point coordinates\n",
    "\n",
    "    # Draw lines between consecutive bullet points\n",
    "    for i in range(1, len(bullet_points)):\n",
    "        cv2.line(frame, bullet_points[i - 1], bullet_points[i], (255, 0, 0), 8)\n",
    "\n",
    "    # Draw bullet points on the frame\n",
    "    for bullet_point in bullet_points:\n",
    "        cv2.circle(frame, bullet_point, 12, (0, 255, 0), -1)\n",
    "\n",
    "    # Flip the frame horizontally to correct the mirror effect\n",
    "    flipped_frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Display the flipped frame\n",
    "    cv2.imshow('Index Finger Movement', flipped_frame)\n",
    "\n",
    "    # Check for key press events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('c'):  # Clear points and lines on 'c' key press\n",
    "        bullet_points = []\n",
    "    elif key == ord('s'):  # Save the lines in a white blank board\n",
    "        capture_image = True\n",
    "\n",
    "    # If capture_image is True, save the frame as an image\n",
    "    if capture_image:\n",
    "        blank_image = np.ones_like(frame) * 255\n",
    "\n",
    "        # Draw the lines on the blank image\n",
    "        for i in range(1, len(bullet_points)):\n",
    "            cv2.line(blank_image, bullet_points[i - 1], bullet_points[i], (0, 0, 0), 2)\n",
    "\n",
    "        non_white_pixels = np.where(np.any(blank_image != 255, axis=-1))\n",
    "\n",
    "        min_y, max_y = non_white_pixels[0].min(), non_white_pixels[0].max()\n",
    "        min_x, max_x = non_white_pixels[1].min(), non_white_pixels[1].max()\n",
    "        cropped_image = blank_image[min_y:max_y + 1, min_x:max_x + 1]\n",
    "\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        desktop_path = os.path.expanduser(\"~\") + \"/Desktop/\"\n",
    "        image_filename = desktop_path + \"captured_lines_\" + timestamp + \".jpg\"\n",
    "        cv2.imwrite(image_filename, cropped_image)\n",
    "        print(\"Lines captured and saved on the desktop!\")\n",
    "\n",
    "        capture_image = False\n",
    "\n",
    "# Release the webcam resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handwritten-paper-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
